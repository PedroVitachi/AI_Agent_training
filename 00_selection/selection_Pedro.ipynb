{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee04aa62",
      "metadata": {
        "id": "ee04aa62"
      },
      "source": [
        "# üìä Challenge ‚Äì Data Science (J√∫nior)\n",
        "\n",
        "Bem-vindo ao **Challenge de Data Science** da BU de Dados e IA da GFT!\n",
        "\n",
        "Este desafio faz parte do nosso processo de sele√ß√£o para integrar a equipe respons√°vel pelo **Agent Factory**, uma iniciativa estrat√©gica com foco em solu√ß√µes de intelig√™ncia baseadas em dados.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objetivo\n",
        "\n",
        "Seu objetivo neste desafio √© construir um modelo simples de **machine learning** utilizando dados reais do ENEM, com o foco em **prever a nota da reda√ß√£o** de um candidato a partir de informa√ß√µes dispon√≠veis no conjunto de dados.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç O que voc√™ vai fazer\n",
        "\n",
        "Voc√™ ser√° respons√°vel por seguir as principais etapas de um projeto de Ci√™ncia de Dados, de forma simples e organizada:\n",
        "\n",
        "### 1. **Carregamento e explora√ß√£o dos dados**\n",
        "\n",
        "* Utilize o dataset que disponibilizamos neste link:\n",
        "* Fa√ßa a leitura, entenda as colunas dispon√≠veis e identifique quais podem ser √∫teis para a tarefa.\n",
        "\n",
        "### 2. **An√°lise explorat√≥ria dos dados (EDA)**\n",
        "\n",
        "* Crie visualiza√ß√µes e tabelas para entender o comportamento das vari√°veis.\n",
        "* Observe poss√≠veis correla√ß√µes com a nota da reda√ß√£o (`NU_NOTA_REDACAO`).\n",
        "* Verifique a exist√™ncia de valores ausentes ou inconsistentes.\n",
        "\n",
        "### 3. **Constru√ß√£o do modelo**\n",
        "\n",
        "Voc√™ pode escolher entre duas abordagens:\n",
        "\n",
        "* **Regress√£o:** prever a nota exata da reda√ß√£o (de 0 a 1000).\n",
        "* **Classifica√ß√£o:** prever a faixa de desempenho da reda√ß√£o (por exemplo):\n",
        "\n",
        "  * **Baixa**: 0‚Äì400\n",
        "  * **M√©dia**: 401‚Äì800\n",
        "  * **Alta**: 801‚Äì1000\n",
        "\n",
        "> Lembre-se principalmente da etapa de Feature Engineering. O dataset tem algumas vari√°veis que, apesar de representadas por valores num√©ricos, s√£o **categ√≥ricas**. Voc√™ dever√° trat√°-las corretamente para adicion√°-las ao modelo, se julgar necess√°rio.\n",
        "\n",
        "### 4. **Avalia√ß√£o do modelo**\n",
        "\n",
        "* Para regress√£o: use m√©tricas como **MAE**, **RMSE** ou **R¬≤**.\n",
        "* Para classifica√ß√£o: utilize **acur√°cia**, **precis√£o**, **recall**, **matriz de confus√£o**, etc.\n",
        "\n",
        "### 5. **Conclus√£o**\n",
        "\n",
        "* Destaque as vari√°veis que mais influenciaram na previs√£o.\n",
        "* Comente o desempenho do modelo e poss√≠veis melhorias.\n",
        "* Aqui o que mais vale √© sua explica√ß√£o. Demonstre que entendeu todo o processo.\n",
        "\n",
        "---\n",
        "\n",
        "## üìÅ Sobre os dados\n",
        "\n",
        "Voc√™ estar√° trabalhando com um dataset real do ENEM 2019, extra√≠do do site do INEP. Para este desafio, selecionamos apenas 10.000 registros e algumas colunas, com o objetivo de n√£o tornar o dataset t√£o pesado para as an√°lises. As colunas selecionadas foram:\n",
        "\n",
        "| Coluna            | Descri√ß√£o                                                                 | Categorias / Valores Poss√≠veis                                                       |\n",
        "|-------------------|---------------------------------------------------------------------------|----------------------------------------------------------------------------------------|\n",
        "| NU_ANO            | Ano de realiza√ß√£o do exame.                                               | Ex: 2019                                                                  |\n",
        "| NU_NOTA_CN        | Nota em Ci√™ncias da Natureza.                                             | Varia entre 0 e 1000                                                                  |\n",
        "| NU_NOTA_CH        | Nota em Ci√™ncias Humanas.                                                 | Varia entre 0 e 1000                                                                  |\n",
        "| NU_NOTA_LC        | Nota em Linguagens e C√≥digos.                                             | Varia entre 0 e 1000                                                                  |\n",
        "| NU_NOTA_MT        | Nota em Matem√°tica.                                                       | Varia entre 0 e 1000                                                                  |\n",
        "| TP_ESCOLA         | Tipo de escola em que o participante concluiu ou est√° concluindo o EM.    | 1: N√£o respondeu <br>2: P√∫blica<br>3: Privada<br>4: Exterior       |\n",
        "| NU_NOTA_REDACAO   | Nota obtida na reda√ß√£o.                                                   | Varia entre 0 e 1000                                                                  |\n",
        "| TP_ST_CONCLUSAO   | Situa√ß√£o de conclus√£o do Ensino M√©dio do participante.                    | 1: J√° conclu√≠<br>2: Estou cursando e vou concluir em 2019<br>3: Estou cursando e vou concluir ap√≥s 2019 <br>4: N√£o conclu√≠ e n√£o estou cursando o Ensino M√©dio|\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Entrega\n",
        "\n",
        "Voc√™ dever√° entregar um **notebook Jupyter (.ipynb)** com:\n",
        "\n",
        "* As an√°lises e visualiza√ß√µes realizadas\n",
        "* O(s) modelo(s) criados\n",
        "* M√©tricas utilizadas para avalia√ß√£o\n",
        "* Conclus√µes finais\n",
        "\n",
        "> Organiza√ß√£o, clareza nos coment√°rios e boas pr√°ticas contam muitos pontos!\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Dicas\n",
        "\n",
        "* Comece com uma amostra menor para explorar os dados mais rapidamente.\n",
        "* Elimine colunas que n√£o fazem sentido (como CPF, nome, c√≥digo da prova, etc.).\n",
        "* Tente diferentes algoritmos, mas priorize o entendimento sobre a complexidade.\n",
        "* Comente cada etapa no seu notebook explicando o que est√° fazendo e porqu√™.\n",
        "* **N√£o se preocupe *tanto* com o resultado final**. O objetivo maior do exerc√≠cio √© avaliar a linha de racioc√≠nio e o pensamento cr√≠tico resolver o case.\n",
        "* Voc√™ pode usar aplica√ß√µes de IA Generativa. No entanto, todas as decis√µes ser√£o questionadas. √â importante entender o que est√° fazendo a todo momento.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Crit√©rios de Avalia√ß√£o\n",
        "\n",
        "* Clareza e organiza√ß√£o do notebook\n",
        "* Qualidade da an√°lise explorat√≥ria\n",
        "* Adequa√ß√£o do modelo e interpreta√ß√£o dos resultados\n",
        "* Justificativa das decis√µes t√©cnicas\n",
        "* Comunica√ß√£o das conclus√µes\n",
        "\n",
        "---\n",
        "\n",
        "Boa sorte, e divirta-se no processo!\n",
        "Estamos ansiosos para ver como voc√™ vai transformar dados em conhecimento. üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86426e6",
      "metadata": {
        "id": "e86426e6"
      },
      "source": [
        "# 0. Imports\n",
        "\n",
        "Fa√ßa aqui nesta se√ß√£o todos os imports que voc√™ precisar. J√° deixamos algumas sugest√µes prontas mas fique a vontade para usar quaisquer outras desejadas :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483ec702",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "483ec702",
        "outputId": "d20f5da4-3e46-4163-a78d-a637548f710c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install numpy\n",
        "%pip install matplotlib\n",
        "%pip install scikit-learn\n",
        "#%pip install xgboost\n",
        "#%pip install seaborn\n",
        "import pandas as pd # Carregamento e manipula√ß√£o de dados\n",
        "import matplotlib as plt # Visualiza√ß√£o\n",
        "import numpy as np # lib para utiliza√ß√£o de opera√ß√µes numericas\n",
        "from sklearn.preprocessing import OneHotEncoder # lib para transformar as vari√°veis categ√≥ricas em colunas bin√°rias que facilitam sua manipula√ß√£o\n",
        "from sklearn.model_selection import train_test_split # lib para separa√ß√£o de de conjunto de dados entre treino e teste, com objetivo de prevenir overfitting\n",
        "from sklearn.impute import SimpleImputer # Preven√ß√£o de dados nulos no modelo\n",
        "from sklearn.compose import ColumnTransformer # lib que permite aplicar transforma√ß√µes diferentes para vari√°veis numericas e categoricas\n",
        "from sklearn.pipeline import Pipeline # clean code\n",
        "from sklearn.linear_model import LinearRegression # lib que implementa coeficientes para as vari√°veis, visando minimizar os erros entre os valores reais e os previstos\n",
        "from sklearn.metrics import mean_absolute_error # Implementa√ß√£o do MAE para mostrar a varian√ßa dos dados previstos com os dados reais\n",
        "from sklearn.metrics import mean_squared_error # Implementa√ß√£o do RMSE para mostrar a varian√ßa dos dados previstos com os dados reais\n",
        "from sklearn.metrics import r2_score # Implementa√ß√£o do R¬≤ para mostrar a varian√ßa dos dados previstos com os dados reais"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d61e6c",
      "metadata": {
        "id": "a5d61e6c"
      },
      "source": [
        "## üìÅ 1. Carregamento e limpeza dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b88d6f1d",
      "metadata": {
        "collapsed": true,
        "id": "b88d6f1d"
      },
      "outputs": [],
      "source": [
        "# remova os coment√°rios para ler o arquivo do github\n",
        "# carregando o dataframe diretamente do github\n",
        "# import pandas as pd\n",
        "# file_path = \"https://raw.githubusercontent.com/silva-raphael/ps-datascience-gft/refs/heads/main/filtered-enem-2019.csv\"\n",
        "\n",
        "# Realizando leitura do dataframe\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/silva-raphael/ps-datascience-gft/refs/heads/main/filtered-enem-2019.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a1dee2",
      "metadata": {
        "id": "b3a1dee2"
      },
      "source": [
        "### Limpeza e tratamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "516d8dd3",
      "metadata": {
        "id": "516d8dd3"
      },
      "outputs": [],
      "source": [
        "# Descartando a vari√°vel NU_ANO, visto que o dataset mant√©m essa informa√ß√£o est√°tica\n",
        "df = df[[\n",
        "    'NU_NOTA_CN',\n",
        "    'NU_NOTA_CH',\n",
        "    'NU_NOTA_LC',\n",
        "    'NU_NOTA_MT',\n",
        "    'TP_ESCOLA',\n",
        "    'NU_NOTA_REDACAO',\n",
        "    'TP_ST_CONCLUSAO'\n",
        "]]\n",
        "\n",
        "# Verifica√ß√£o de campos nulos, caso existam, eu devo substitui-los por outro valor para n√£o afetar no algoritmo\n",
        "df.isnull().sum()\n",
        "\n",
        "# Remo√ß√£o da NU_NOTA_REDACAO do dataframe, X recebendo o dataframe inteiro exceto NU_NOTA_REDACAO, e y contendo a totalidade da NU_NOTA_REDACAO\n",
        "X = df.drop('NU_NOTA_REDACAO', axis=1)\n",
        "y = df['NU_NOTA_REDACAO']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19929614",
      "metadata": {
        "id": "19929614"
      },
      "source": [
        "### Visualiza√ß√µes iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e0ed93",
      "metadata": {
        "id": "42e0ed93"
      },
      "outputs": [],
      "source": [
        "# Classificando as vari√°veis num√©ricas e as categ√≥ricas\n",
        "numericas = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT']\n",
        "categoricas = ['TP_ESCOLA', 'TP_ST_CONCLUSAO']\n",
        "\n",
        "# O OneHotEncoder transforma as vari√°veis categ√≥ricas em colunas bin√°rias, visando evitar confus√µes no algoritmo, visto que essas vari√°veis vao divergir dos valores de nota que ser√£o pesados para prever o valor da nota da reda√ß√£o\n",
        "cat_pipeline = Pipeline([\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# O ColumnTransformer foi utilizado para aplicar transforma√ß√µes diferentes para cada tipo de vari√°vel, para prosseguir com o uso delas na pipeline\n",
        "preprocessamento = ColumnTransformer([\n",
        "    ('num', 'passthrough', numericas), # Passa as vari√°veis num√©ricas diretamente, da maneira que est√£o no dataframe\n",
        "    ('cat', cat_pipeline, categoricas) # Passa as vari√°veis categoricas com o OneHotEncoder aplicado\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470f26b4",
      "metadata": {
        "id": "470f26b4"
      },
      "source": [
        "## ü§ñ 2. An√°lise explorat√≥ria dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e96c80",
      "metadata": {
        "id": "b3e96c80"
      },
      "outputs": [],
      "source": [
        "# Cria√ß√†o da pipeline, usando os dados tratados anteriormente, e aplicando a equa√ß√£o de regress√†o linear\n",
        "modelo = Pipeline([\n",
        "    ('preprocessamento', preprocessamento), # Objeto definido anteriormente, contendo as colunas transformadas por tipo de vari√°vel\n",
        "    ('regressor', LinearRegression()) # Aplica o modelo de regress√£o linear, usando a equa√ß√£o para chegar no valor previsto da NU_NOTA_REDACAO com base nos coeficientes num√©ricos (outras notas) + as vari√°veis categ√≥ricas\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a68d34",
      "metadata": {
        "id": "b3a68d34"
      },
      "source": [
        "## üß™ 3. Constru√ß√£o do modelo (Treinamento e avalia√ß√£o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1b5165",
      "metadata": {
        "id": "ad1b5165"
      },
      "outputs": [],
      "source": [
        "# Aplica√ß√£o do train_test_split, que separa a massa em 20% (test_size=0.2) para testes e o restante para treinamento, visando treinar o modelo com uma fatia dos dados, e em seguida testar o desempenho do modelo com uma parte dos dados que ainda n√£o foi vista pelo modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Achei bizarro o 42 sert√£o comum como divisor nas aulas que assisti e basicamente em toda aplica√ß√£o de treinamento, tive que pesquisar para entender por que tanta gente usa o 42 e n√£o me decepcionei\n",
        "\n",
        "# Treinamento do modelo usando as vari√°veis de treinamento separadas anteriormente\n",
        "modelo.fit(X_train, y_train) # o m√©todo .fit() ir√° treinar o modelo a prever a vari√°vel y (NU_NOTA_REDACAO) baseado nos coeficientes X previamente estabelecidos pelo LinearRegression()\n",
        "\n",
        "# Agora que o treinamento est√° conclu√≠do, podemos prosseguir com a aplica√ß√£o das m√©tricas\n",
        "y_pred = modelo.predict(X_test) # ir√° fazer previs√µes com os dados de teste que ainda n√£o foram vistos no treinamento do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb8ed85",
      "metadata": {
        "id": "0cb8ed85"
      },
      "source": [
        "## üß† 4. Avalia√ß√£o do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c78913a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c78913a",
        "outputId": "f4c4ae83-0fff-4d8c-cacb-209948b1f3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 105.40\n",
            "RMSE: 142.01\n",
            "R¬≤: 0.37\n"
          ]
        }
      ],
      "source": [
        "# MAE\n",
        "mae = mean_absolute_error(y_test, y_pred) # Aplica a metrica Erro M√©dio Absoluto, que visa contabilizar a variancia entre a previs√£o do modelo com os dados reais a partir dos erros absolutos\n",
        "print(f\"MAE: {mae:.2f}\") # exibe o valor do erro m√©dio em pontos da reda√ß√£o\n",
        "\n",
        "#RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # Similar ao MAE, ele tamb√©m calcula a vari√¢ncia com base nos erros, por√©m consegue pegar os casos mais extremos (outliers) por elevar as m√©tricas ao quadrado, expondo os outliers, igual o MSE, por√©m ao aplicar a raiz quadrada √© poss√≠vel visualizar a vari√¢ncia na mesma escala que os dados originais\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "\n",
        "#R¬≤\n",
        "r2 = r2_score(y_test, y_pred) # M√©trica que representa o percentual da vari√¢ncia dos dados em porcentagem\n",
        "print(f\"R¬≤: {r2:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a581949",
      "metadata": {
        "id": "5a581949"
      },
      "source": [
        "## üó£Ô∏è 5. Conclus√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como deu para ver eu n√£o tenho muito conhecimento na ci√™ncia de dados, maioria dos meus coment√°rios estavam servindo como fixadores para eu entender melhor o que cada m√©todo estava fazendo e explicando qual a raz√£o de utilizar eles.\n",
        "\n",
        "N√£o tenho o conhecimento necess√°rio ainda para entender como melhorar a vari√¢ncia das previs√µes sem ter uma massa de dados maior, por√©m estou com bastante interesse em continuar aprendendo mais sobre o assunto, que acabou me interessando bastante, mesmo sendo diferente da engenharia de dados que eu estava estudando previamente (como os dados estavam bem limpos n√£o teve muita coisa a ser cortada)."
      ],
      "metadata": {
        "id": "1tuwa9fg4iea"
      },
      "id": "1tuwa9fg4iea"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}